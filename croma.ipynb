{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "from pprint import pprint\n",
    "client=chromadb.Client()\n",
    "collection=client.get_or_create_collection(name=\"prod\")\n",
    "\n",
    "\n",
    "with open('./productList.json', 'r') as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "data = json.loads(json_data)\n",
    "pprint(data)\n",
    "\n",
    "document_to_add=[]\n",
    "metadata_to_add=[]\n",
    "embeddings_to_add=[]\n",
    "ids_to_add=[]\n",
    "\n",
    "# # Assume the JSON data is already provided in `data`\n",
    "# products = data[\"product\"]\n",
    "\n",
    "# # Initialize lists for documents, metadata, IDs, and keywords\n",
    "# documents = []\n",
    "# metadata = []\n",
    "# ids = []\n",
    "# keywords = []\n",
    "\n",
    "# # Iterate through each product and extract the required information\n",
    "# for product in products:\n",
    "#     doc = {\n",
    "#         \"name\": product[\"name\"],\n",
    "#         \"description\": product[\"description\"],\n",
    "#         \"price\": product[\"price\"],\n",
    "#         \"image_path\": product[\"image_path\"],\n",
    "#         \"company_name\": product[\"company_id\"][\"name\"],\n",
    "#         \"category_name\": product[\"category_id\"][\"name\"],\n",
    "#         \"subcategory_name\": product[\"subcategory_id\"][\"name\"],\n",
    "#         \"sticker_path\": product[\"sticker_path\"]\n",
    "#     }\n",
    "#     meta = {\n",
    "#         \"company_description\": product[\"company_id\"][\"description\"],\n",
    "#         \"company_contact\": product[\"company_id\"][\"company_contact\"],\n",
    "#         \"company_email\": product[\"company_id\"][\"company_email\"],\n",
    "#         \"company_location\": product[\"company_id\"][\"location_details\"][0][\"address\"],\n",
    "#         \"category_description\": product[\"category_id\"][\"description\"],\n",
    "#         \"subcategory_description\": product[\"subcategory_id\"][\"description\"]\n",
    "#     }\n",
    "#     document_id = product[\"_id\"]\n",
    "#     product_keywords = product[\"keyword\"]\n",
    "\n",
    "#     documents.append(doc)\n",
    "#     metadata.append(meta)\n",
    "#     ids.append(document_id)\n",
    "#     keywords.extend(product_keywords)\n",
    "\n",
    "# collection.add( documents=documents,metadatas=metadata,ids=ids)\n",
    "# # Output the lists for verification\n",
    "# print(\"Documents:\", documents)\n",
    "# print(\"Metadata:\", metadata)\n",
    "# print(\"IDs:\", ids)\n",
    "# print(\"Keywords:\", keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chromadb.utils import embedding_functions\n",
    "\n",
    "# # Sample JSON data\n",
    "# products = data[\"product\"]\n",
    "\n",
    "# # Initialize lists for documents, metadata, IDs, and keywords\n",
    "# documents = []\n",
    "# metadata = []\n",
    "# ids = []\n",
    "# keywords = []\n",
    "# students_embedd = []\n",
    "\n",
    "# # Initialize your OpenAI embedding function\n",
    "# openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "#     api_key=\"API key\",\n",
    "#     model_name=\"text-embedding-3-small\"\n",
    "# )\n",
    "\n",
    "# # Iterate through each product and extract the required information\n",
    "# test_arr_2 = []\n",
    "# for product in products:\n",
    "#     doc = {\n",
    "#         \"name\": product[\"name\"],\n",
    "#         \"description\": product[\"description\"],\n",
    "#         \"price\": product[\"price\"],\n",
    "#         \"image_path\": product[\"image_path\"],\n",
    "#         \"company_name\": product[\"company_id\"][\"name\"],\n",
    "#         \"category_name\": product[\"category_id\"][\"name\"],\n",
    "#         \"subcategory_name\": product[\"subcategory_id\"][\"name\"]\n",
    "#     }\n",
    "#     doc_str = ', '.join([f\"'{key}': '{value}'\" for key, value in doc.items()])\n",
    "   \n",
    "#     test_arr_2.append([f\"'{key}': '{value}'\" for key, value in doc.items()])\n",
    "#     documents.append(doc_str)\n",
    "#     # Obtain embeddings for the product using your OpenAI function\n",
    "#     # Append embeddings as they are\n",
    "\n",
    "#     meta = {\n",
    "#         \"company_description\": product[\"company_id\"][\"description\"],\n",
    "#         \"company_contact\": product[\"company_id\"][\"company_contact\"],\n",
    "#         \"company_email\": product[\"company_id\"][\"company_email\"],\n",
    "#         \"company_location\": product[\"company_id\"][\"location_details\"][0][\"address\"],\n",
    "#         \"category_description\": product[\"category_id\"][\"description\"],\n",
    "#         \"subcategory_description\": product[\"subcategory_id\"][\"description\"]\n",
    "#     }\n",
    "#     meta_str = ', '.join([f\"{key}': '{value}'\" for key, value in meta.items()])\n",
    "#     metadata.append(meta_str)\n",
    "\n",
    "#     document_id = product[\"_id\"]\n",
    "#     product_keywords = product[\"keyword\"]\n",
    "#     ids.append(document_id)\n",
    "#     keywords.append(product_keywords)\n",
    "# # test_arr = []\n",
    "# # test_arr.append(test_arr_2)\n",
    "# # pprint(test_arr_2)\n",
    "# # Adding data to the collection (adjust as per your implementation)\n",
    "\n",
    "# students_embeddings = openai_ef([test_arr_2])\n",
    "# #pprint([test_arr_2])\n",
    "# # Output the lists for verification\n",
    "# # print(\"Documents:\", documents)\n",
    "# # print(\"Metadata:\", metadata)\n",
    "# # print(\"IDs:\", ids)\n",
    "# # print(\"Keywords:\", keywords)\n",
    "#   # Verify embeddings format\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Sample JSON data\n",
    "products = data[\"product\"]\n",
    "\n",
    "# Initialize lists for documents, metadata, IDs, and keywords\n",
    "documents = []\n",
    "metadata = []\n",
    "ids = []\n",
    "keywords = []\n",
    "students_embedd = []\n",
    "\n",
    "# Initialize your OpenAI embedding function\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=\"API key\",\n",
    "    model_name=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "# Iterate through each product and extract the required information\n",
    "test_arr_2 = []\n",
    "for product in products:\n",
    "    doc = {\n",
    "        \"name\": product[\"name\"],\n",
    "        \"description\": product[\"description\"],\n",
    "        \"price\": product[\"price\"],\n",
    "        \"Keywords\": product[\"keyword\"],\n",
    "        \"image_path\": product[\"image_path\"],\n",
    "        \"company_name\": product[\"company_id\"][\"name\"],\n",
    "        \"category_name\": product[\"category_id\"][\"name\"],\n",
    "        \"subcategory_name\": product[\"subcategory_id\"][\"name\"]\n",
    "    }\n",
    "    doc_str = ', '.join([f\"'{key}': '{value}'\" for key, value in doc.items()])\n",
    "    test_arr_2.append(doc_str)  # Store the concatenated string instead of list of key-value pairs\n",
    "    documents.append(doc_str)\n",
    "\n",
    "    meta = {\n",
    "        \"company_description\": product[\"company_id\"][\"description\"],\n",
    "        \"company_contact\": product[\"company_id\"][\"company_contact\"],\n",
    "        \"company_email\": product[\"company_id\"][\"company_email\"],\n",
    "        # \"company_location\": product[\"company_id\"][\"location_details\"][0][\"address\"],\n",
    "        \"category_description\": product[\"category_id\"][\"description\"],\n",
    "        \"subcategory_description\": product[\"subcategory_id\"][\"description\"]\n",
    "    }\n",
    "    meta_str = ', '.join([f\"'{key}': '{value}'\" for key, value in meta.items()])\n",
    "    metadata.append(meta_str)\n",
    "\n",
    "    document_id = product[\"_id\"]\n",
    "    product_keywords = product[\"keyword\"]\n",
    "    ids.append(document_id)\n",
    "    keywords.append(product_keywords)\n",
    "\n",
    "# Obtain embeddings for the concatenated product information\n",
    "students_embeddings = openai_ef(test_arr_2)  # Pass a list of strings\n",
    "\n",
    "# Append embeddings to students_embedd\n",
    "students_embedd.append(students_embeddings)\n",
    "\n",
    "# Output the lists for verification\n",
    "print(\"Documents:\", documents)\n",
    "print(\"Metadata:\", metadata)\n",
    "print(\"IDs:\", ids)\n",
    "print(\"Keywords:\", keywords)\n",
    "print(\"Embeddings:\", students_embedd)  # Verify embeddings format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(students_embeddings)\n",
    "collection.add( ids=ids, embeddings=students_embeddings,documents=documents)\n",
    "# pprint(students_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the collection\n",
    "query_text = [\"Should you have a gun\"]\n",
    "# Split the query text into individual words\n",
    "words = query_text[0].split()\n",
    "\n",
    "# Create the filter using the `$or` operator\n",
    "filter_dict = {\"$or\": [{\"$contains\": word} for word in words]}\n",
    "query_embeddings = openai_ef(query_text)\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embeddings, # Chroma will embed this for you\n",
    "    where_document=filter_dict,\n",
    "    n_results=1\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromadb.utils.embedding_functions as embedding_functions\n",
    "# openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "#                 api_key=\"API keyproj-eYPtSm0HCAA\",\n",
    "#                 model_name=\"text-embedding-3-small\"\n",
    "#             )\n",
    "\n",
    "# val = openai_ef([\"prod\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "# class MyEmbeddingFunction(EmbeddingFunction):\n",
    "#     def __call__(self, input:Documents) -> Embeddings:\n",
    "#         openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "#                 api_key=\"API keyproj-eYPtSOAA\",\n",
    "#                 model_name=\"text-embedding-3-small\"\n",
    "#             )\n",
    "\n",
    "#         val = openai_ef([\"prod\"])\n",
    "#         return val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_collections()\n",
    "# client.delete_collection(\"prod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedd=val[0]\n",
    "# collection.add(\n",
    "#     documents=documents,\n",
    "#     embeddings=embedd,\n",
    "#     ids=ids\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(val)\n",
    "# pprint(embedd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromadb.utils.embedding_functions as embedding_functions\n",
    "\n",
    "# # Initialize the OpenAI embedding function\n",
    "# openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "#     api_key=\"API key\",\n",
    "#     model_name=\"text-embedding-3-small\"\n",
    "# )\n",
    "\n",
    "# # Function to generate embeddings for each product\n",
    "# def generate_product_embeddings(data):\n",
    "#     product_embeddings = {}\n",
    "    \n",
    "#     for product in data:\n",
    "#         product_id = product[\"_id\"]\n",
    "        \n",
    "#         # Combine the relevant text fields\n",
    "#         text_to_embed = product[\"name\"] + \" \" + product[\"description\"] + \" \" + str(product[\"price\"]) + \" \" + \" \".join(product[\"keyword\"])\n",
    "        \n",
    "#         # Generate embedding\n",
    "#         embedding = openai_ef([text_to_embed])[0]\n",
    "        \n",
    "#         # Store embedding with product ID\n",
    "#         product_embeddings[product_id] = embedding\n",
    "    \n",
    "#     return product_embeddings\n",
    "\n",
    "# # Assume products data is already provided\n",
    "# product_embeddings = generate_product_embeddings(products)\n",
    "\n",
    "# # Print the generated embeddings\n",
    "# for product_id, embedding in product_embeddings.items():\n",
    "#     print(f\"Product ID: {product_id}, Embedding: {embedding[:2]}...\")  # Printing first 10 values of the embedding for brevity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(students_embedd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(students_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install haversine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import haversine as hs   \n",
    "# from haversine import Unit\n",
    " \n",
    "# loc1=(31.511327, 74.342059)\n",
    "# loc2=(31.526437, 74.352327)\n",
    " \n",
    "# result=hs.haversine(loc1,loc2,unit=Unit.KILOMETERS)\n",
    "# print(\"The distance calculated is:\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from openai import OpenAI\n",
    "## Conversational Q&A Chatbot\n",
    "import streamlit as st\n",
    "\n",
    "## Streamlit UI\n",
    "st.set_page_config(page_title=\"Conversational Q&A Chatbot\")\n",
    "st.header(\"Hey, Let's Chat\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=\"API key\")\n",
    "\n",
    "api_key = \"API key\"\n",
    "if not api_key:\n",
    "    st.error(\"OpenAI API key not found. Please set it in the .env file.\")\n",
    "    st.stop()\n",
    "\n",
    "search_text = \"burgers\"\n",
    "# Calculate distances and find closest product that matches search term\n",
    "def correct_spelling(inp):\n",
    "    response = client.chat.completions.create( \n",
    "                            model=\"gpt-3.5-turbo\", \n",
    "                            messages=[{\"role\": \"system\", \"content\": \"You Extract keywords from the provide sentence after the correction of Spelling and grammar checking and provide the resulted keywords with comma separated.\"}, \n",
    "                                      {\"role\": \"user\", \"content\": inp}] ) \n",
    "    \n",
    "    corrected_text =response.choices[0].message.content\n",
    "    return corrected_text\n",
    "\n",
    "\n",
    "corrected_search_text = correct_spelling(search_text)\n",
    "\n",
    "print(\"Corrected search text:\", corrected_search_text)\n",
    "\n",
    "# Query the collection\n",
    "def search_Result(inp):\n",
    "    query_text = [inp]\n",
    "\n",
    "    query_embeddings = openai_ef(query_text)\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_embeddings, # Chroma will embed this for you\n",
    "        n_results=1  \n",
    "    )\n",
    "    return results\n",
    "\n",
    "# input=st.text_input(\"Input: \",key=\"input\")\n",
    "input=\"shirt\"\n",
    "response_After_correction=correct_spelling(input)\n",
    "searchresult=search_Result(response_After_correction)\n",
    "document_str = searchresult['documents'][0][0]\n",
    "# Check if any results are returned\n",
    "if len(searchresult['documents'][0][0]) == 0:\n",
    "    st.subheader(\"The Response is\")\n",
    "    st.write(\"No product Found!\")\n",
    "else:\n",
    "     # Convert the string representation of the dictionary into an actual dictionary\n",
    "    document_dict = ast.literal_eval(\"{\" + document_str + \"}\")\n",
    "    # Extract and print the name, description, and price\n",
    "    name = document_dict.get('name')\n",
    "    description = document_dict.get('description')\n",
    "    price = document_dict.get('price')\n",
    "    search_Result_str = f\"Name: {name}\\nDescription: {description}\\nPrice: {price}\"    \n",
    "\n",
    "\n",
    "\n",
    "submit=st.button(\"Ask the question\")\n",
    "\n",
    "print(search_Result_str)\n",
    "if submit:\n",
    "    st.subheader(\"The Response is\")\n",
    "    st.write(search_Result_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
