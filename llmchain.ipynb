{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPEN_API_KEY\"]=\"API key\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"What is the capital of Pakistan\"\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=['country'],\n",
    "template=\"Tell me the capital of this {country}\")\n",
    "\n",
    "prompt_template.format(country=\"Pakistan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain=LLMChain(llm=llm,prompt=prompt_template)\n",
    "print(chain.run(\"Pakistan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n",
    "chatllm=ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6,model='gpt-3.5-turbo')\n",
    "chatllm([\n",
    "SystemMessage(content=\"Yor are a comedian AI assitant\"),\n",
    "HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=\"API key\")\n",
    "\n",
    "# Load the product list from the JSON file\n",
    "with open('productList.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the products list\n",
    "products = data.get('product', [])\n",
    "\n",
    "# Prepare a list to store embeddings and product names for visualization\n",
    "embeddings_list = []\n",
    "product_names = []\n",
    "\n",
    "# Function to create a concatenated string for embedding\n",
    "def create_text_for_embedding(product):\n",
    "    name = product.get('name', '')\n",
    "    description = product.get('description', '')\n",
    "    price = f\"Price: ${product.get('price', 'N/A')}\"\n",
    "    \n",
    "    # Extract location details, including latitude and longitude\n",
    "    location_details = product.get('company_id', {}).get('location_details', [])\n",
    "    location_texts = [\n",
    "        f\"Location: {loc.get('name', '')}, {loc.get('address', '')}, Latitude: {loc.get('latitude', 'N/A')}, Longitude: {loc.get('longitude', 'N/A')}\" \n",
    "        for loc in location_details\n",
    "    ]\n",
    "    location_text = ' | '.join(location_texts)\n",
    "    \n",
    "    # Extract category and subcategory\n",
    "    category_name = product.get('category_id', {}).get('name', '')\n",
    "    category_description = product.get('category_id', {}).get('description', '')\n",
    "    category_text = f\"Category: {category_name} - {category_description}\"\n",
    "    \n",
    "    subcategory_name = product.get('subcategory_id', {}).get('name', '')\n",
    "    subcategory_description = product.get('subcategory_id', {}).get('description', '')\n",
    "    subcategory_text = f\"Subcategory: {subcategory_name} - {subcategory_description}\"\n",
    "    \n",
    "    # Combine all parts into one string\n",
    "    combined_text = f\"{name}. {description}. {price}. {location_text}. {category_text}. {subcategory_text}.\"\n",
    "    return combined_text\n",
    "\n",
    "# Iterate through each product and get embeddings\n",
    "for idx, product in enumerate(products):\n",
    "    text_to_embed = create_text_for_embedding(product)\n",
    "    if text_to_embed:\n",
    "        try:\n",
    "            # Create the embedding\n",
    "            response = client.embeddings.create(model=\"text-embedding-3-small\", input=text_to_embed)\n",
    "            embedding = response.data[0].embedding\n",
    "            product['embedding'] = embedding  \n",
    "            embeddings_list.append(embedding)  \n",
    "            product_names.append(product.get('name', 'Unnamed'))  \n",
    "            print(f\"Processed product {idx+1}/{len(products)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process product {idx+1}/{len(products)}: {e}\")\n",
    "\n",
    "# Save the updated product list with embeddings back to a JSON file\n",
    "with open('product_list_with_embeddings.json', 'w') as file:\n",
    "    json.dump(products, file, indent=2)\n",
    "\n",
    "# Assuming embeddings_list contains your embeddings data\n",
    "embeddings_array = np.array(embeddings_list)\n",
    "\n",
    "# Check the shape of embeddings_array to understand its structure\n",
    "print(\"Shape of embeddings_array:\", embeddings_array.shape)\n",
    "\n",
    "# Determine perplexity based on the number of samples\n",
    "perplexity = min(30, embeddings_array.shape[0] - 1)\n",
    "# Apply t-SNE to reduce dimensions to 2D\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(embeddings_array)\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
    "\n",
    "# Annotate each point with the corresponding product name\n",
    "for i, name in enumerate(product_names):\n",
    "    plt.annotate(name, (embeddings_2d[i, 0], embeddings_2d[i, 1]), fontsize=8, alpha=0.7)\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('t-SNE Visualization of Product Embeddings')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "# setup Chroma in-memory, for easy prototyping. Can add persistence easily!\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create collection. get_collection, get_or_create_collection, delete_collection also available!\n",
    "collection = client.create_collection(\"all-my-documents\")\n",
    "\n",
    "# Add docs to the collection. Can also update and delete. Row-based API coming soon!\n",
    "collection.add(\n",
    "    documents=[\"This is document1\", \"This is document2\"], # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "    metadatas=[{\"source\": \"notion\"}, {\"source\": \"google-docs\"}], # filter on these!\n",
    "    ids=[\"doc1\", \"doc2\"], # unique for each doc\n",
    ")\n",
    "\n",
    "# Query/search 2 most similar results. You can also .get by id\n",
    "results = collection.query(\n",
    "    query_texts=[\"This is a query document\"],\n",
    "    n_results=2,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from chromadb.api.fastapi import FastAPI as ChromaFastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "chroma_api = ChromaFastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Chroma DB FastAPI Server is running\"}\n",
    "\n",
    "app.include_router(chroma_api.router)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.Client(\n",
    "    chroma_api_impl=\"chromadb.api.fastapi.FastAPI\",\n",
    "    server_url=\"http://127.0.0.1:8000\"\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "client.persist(path=r\"C:\\Users\\DELL\\Desktop\\chatbot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
